# -*- coding: utf-8 -*-
"""DecisionTree.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gHDAu0QYiv_3nOy_NhgJMqLDXqq2Kloc
"""

from sklearn.datasets import load_iris
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import confusion_matrix
from sklearn.model_selection import train_test_split, cross_val_score, KFold

iris = load_iris()
X = iris.data
Y = iris.target
X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size=0.2)
Tree_1 = DecisionTreeClassifier()
Tree_1.fit(X_train, y_train)
y_pred = Tree_1.predict(X_test)
kfold = KFold(n_splits=10)
print(confusion_matrix(y_test, y_pred))
print(cross_val_score(Tree_1, X, Y, cv=kfold))
print(Tree_1.score(X_train, y_train))

from sklearn.datasets import fetch_california_housing
from sklearn.neighbors import KNeighborsRegressor
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import train_test_split, cross_val_score, KFold
import matplotlib.pyplot as plt

Housing_Data = fetch_california_housing()
X = Housing_Data.data
Y = Housing_Data.target
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size =0.2)

KNN_1 = KNeighborsRegressor()
KNN_1.fit(X_train, Y_train)
y_pred = KNN_1.predict(X_test)
kfold = KFold(n_splits=10)
print(mean_squared_error(Y_test, y_pred))
print(cross_val_score(KNN_1, X, Y, cv=kfold))
print(KNN_1.score(X_train, Y_train))

plt.scatter(Y_test, y_pred)
plt.show()
